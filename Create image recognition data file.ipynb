{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import unicodedata as ud\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(input: str) -> str:\n",
    "    return ud.normalize('NFC', input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "with open('matched_names.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        row = [norm(x) for x in row]\n",
    "        if row[0] and row[2]:\n",
    "            mapping[row[0].replace('_', '').replace(' ', '').strip()] = row[2].replace('_', '').replace(' ', '').strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data = {}\n",
    "with open('pricing_data.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        encar_name = norm(row[0].replace('_', '').replace(' ', ''))\n",
    "        if encar_name in mapping:\n",
    "            pricing_data[mapping[encar_name]] = int(row[1].replace(',', ''))\n",
    "        \n",
    "                  \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col(col) -> int:\n",
    "    if col:\n",
    "        return int(col)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def to_int(input: str) -> int:\n",
    "    return int(input.lower().replace(',', '').replace('mm', '').replace('kg', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = {}\n",
    "jsm_to_encar = {}\n",
    "encar_to_jsm = {}\n",
    "encarbroad_to_jsm = {}\n",
    "with open('specs.csv') as csv_file:\n",
    "    next(csv_file)\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if len(row) >= 6 and row[2] and row[3] and row[4]:\n",
    "            encar_name = norm(row[1].replace('_', '').replace(' ', ''))\n",
    "            normalized = norm(row[2])\n",
    "            if '현재' in normalized:\n",
    "                i_ref = normalized.find('현재')\n",
    "                i_start = i_ref - 5\n",
    "                i_end = i_ref + 3\n",
    "                date_part = normalized[i_start:i_end]\n",
    "            elif '년)' in normalized:\n",
    "                i_ref = normalized.find('년)')\n",
    "                i_start = i_ref - 6\n",
    "                i_end = i_ref + 2\n",
    "                date_part = normalized[i_start:i_end]\n",
    "            \n",
    "            words = normalized.replace(date_part, '').split('_')\n",
    "            \n",
    "            encarbroad = norm(row[1].replace('_', '').replace(' ', ''))\n",
    "            \n",
    "            jsm_name = norm(row[2].replace('_', '').replace(' ', ''))\n",
    "            spec_data[jsm_name] = {\n",
    "                'url1': row[3],\n",
    "                'url2': row[4],\n",
    "                'col': get_col(row[5]),\n",
    "                'encar': encar_name,\n",
    "                'encarbroad': encarbroad,\n",
    "                'major_name': norm(' '.join([words[0]] + words[2:-1])),\n",
    "                'minor_name': norm(words[-1]),\n",
    "                'date_part': date_part,\n",
    "            }\n",
    "            jsm_to_encar[jsm_name] = encar_name\n",
    "            \n",
    "            if encar_name in encar_to_jsm:\n",
    "                encar_to_jsm[encar_name].append(jsm_name)\n",
    "                encar_to_jsm[encar_name] = list(set(encar_to_jsm[encar_name]))\n",
    "            else:\n",
    "                encar_to_jsm[encar_name] = [jsm_name]\n",
    "                \n",
    "            if encarbroad in encarbroad_to_jsm:\n",
    "                encarbroad_to_jsm[encarbroad].append(jsm_name)\n",
    "                encarbroad_to_jsm[encarbroad] = list(set(encarbroad_to_jsm[encarbroad]))\n",
    "            else:\n",
    "                encarbroad_to_jsm[encarbroad] = [jsm_name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scraped = {}\n",
    "full_data = {}\n",
    "for name in spec_data:\n",
    "    if name not in pricing_data or name in already_scraped:\n",
    "        continue\n",
    "    url = spec_data[name]['url1']\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    stats = [x.get_text() for x in soup.find_all('dl', class_='detail_lst')[0].find_all('dd')]\n",
    "    \n",
    "    car_spec = {\n",
    "        'fuelEfficiency': stats[0],\n",
    "        'fuel': stats[1],\n",
    "        'horsepower': stats[2],\n",
    "    }\n",
    "    \n",
    "    url = spec_data[name]['url2']\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    col = soup.find_all('div', class_='lineup_btm_td')[spec_data[name]['col'] - 1]\n",
    "    list_items = [x.get_text().strip() for x in col.find_all('li')]\n",
    "    list_items = [x for x in list_items if (x == '정보없음') or (('mm' in x or 'kg' in x) and ('kg.' not in x and 'inch' not in x))]\n",
    "    \n",
    "    car_spec['sideOuter'] = list_items[0]\n",
    "    car_spec['frontOuter'] = list_items[1]\n",
    "    car_spec['frontHeight'] = list_items[2]\n",
    "    car_spec['sideInner'] = list_items[3]\n",
    "    car_spec['frontInner'] = list_items[4]\n",
    "    car_spec['backInner'] = list_items[5]\n",
    "    car_spec['weight'] = list_items[6]\n",
    "    \n",
    "    car_spec['price'] = pricing_data[name]\n",
    "    car_spec['name'] = name\n",
    "    car_spec['majorName'] = spec_data[name]['major_name']\n",
    "    car_spec['minorName'] = spec_data[name]['minor_name']\n",
    "    car_spec['datePart'] = spec_data[name]['date_part']\n",
    "    \n",
    "    full_data[name] = car_spec\n",
    "    \n",
    "    \n",
    "    already_scraped[name] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/Volumes/TriveStorage/code/trive-image-recognition/complete_manual/encar_latest/images'\n",
    "\n",
    "data = {}\n",
    "\n",
    "for img in os.listdir(src):\n",
    "    if img == '.DS_Store' or 'CARMODOO' in img:\n",
    "        continue\n",
    "    [vehicle_class, vehicle_year, image_name] = img.split('xxxxx')\n",
    "    vehicle_class = norm(vehicle_class)\n",
    "    vehicle_year = norm(vehicle_year)\n",
    "\n",
    "    if vehicle_class == None or vehicle_year == None:\n",
    "        continue\n",
    "\n",
    "    if '(' in vehicle_year:\n",
    "        to_remove = vehicle_year[vehicle_year.find('년')+1:vehicle_year.find('(')]\n",
    "        vehicle_year = vehicle_year.replace(to_remove, '')\n",
    "    elif '년' in vehicle_year:\n",
    "        vehicle_year = vehicle_year[:vehicle_year.find('년')+1]\n",
    "        \n",
    "    label_1 = vehicle_class.replace('_', '').replace(' ', '')\n",
    "    label_2 = f'{vehicle_class}{vehicle_year}'.replace('_', '').replace(' ', '')\n",
    "    data[img] = {\n",
    "        'original': img,\n",
    "        'label_1': label_1,\n",
    "        'label_2': label_2,\n",
    "    }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    if data[key]['label_2'] in mapping:\n",
    "        data[key]['mapping'] = mapping[data[key]['label_2']]\n",
    "    elif data[key]['label_1'] in mapping:\n",
    "        data[key]['mapping'] = mapping[data[key]['label_1']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mapped = {}\n",
    "for key in data:\n",
    "    if 'mapping' in data[key] and data[key]['mapping'] in jsm_to_encar:\n",
    "        images_mapped[norm(data[key]['original']).replace(' ', '')] = [full_data[x] for x in encar_to_jsm[jsm_to_encar[data[key]['mapping']]] if x in full_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with io.open('images_mapped.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(images_mapped, ensure_ascii=False))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in images_mapped:\n",
    "    \n",
    "#     print(key, len(images_mapped[key]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
