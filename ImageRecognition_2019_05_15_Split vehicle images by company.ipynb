{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Vehicle Images by Company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Abstract*\n",
    "\n",
    "> The purpose of this notebook is to split up vehicle images by their respective web platforms. We found that a significant amount of the image data that we scraped was unreliable (i.e. the vehicle was wrongly labeled on the scraped platform). In order to isolate the problem (i.e. figure out which platforms and which vehicle models are the most unreliable), we decided to again consolidate all vehicle image data into the encar categories, but this time split up each data set into their respective web platforms (e.g. spcarz, chacourt, kauctioncar, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Introduction*\n",
    "\n",
    "> In order to ensure maximum accuracy for our vehicle image classifier, we need to make sure that the label on each vehicle image is correct. Late in the process we realized that our image scraper was pulling in advertisement images that resided on the same page as the actual vehicle images we were trying to scrape. For example, directly below is an example of the image gallery we are trying to extract from a vehicle details page.\n",
    "\n",
    "![desired](images/desired-vehicle-images.png)\n",
    "\n",
    "> Here is an example of some advertisement images we pull in by mistake.\n",
    "\n",
    "![undesired](images/undesired-ad-images.png)\n",
    "\n",
    "> This problem does not seem to show up frequently, and it is not clear why it arises for some vehicle class and not for others. Nevertheless, because of how important it is to maintain proper labeling of our data set, we decided to err on the side of caution, and identify exactly which company websites were the most problematic (data organization example directly below).\n",
    "\n",
    "```\n",
    "Used Car Company Name\n",
    "│   * chacha\n",
    "│   * kauctioncar\n",
    "│   * jchere\n",
    "│   * chacourt\n",
    "│   * usedcarmall\n",
    "│   * jcpremium\n",
    "│   * encar\n",
    "│   * bobaedream\n",
    "│\n",
    "└───Vehicle Class\n",
    "    │   * 푸조_2008_2008(13년~현재)\n",
    "    │   * 푸조_206_206CC(00~08년)\n",
    "    │   * 푸조_207_207CC(06~13년)\n",
    "    │   * 푸조_208_208(13년~현재)\n",
    "    │   * ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Method*\n",
    "\n",
    "> Please refer to the Python code below to see my methods for achieving the goals set out in the `Introduction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies here\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "import typing as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping of all data sources and all data destinations\n",
    "# absolute path to root directory for this project\n",
    "cwd = os.getcwd()\n",
    "dst = os.path.join(cwd, 'images-by-company')\n",
    "\n",
    "def make_src(path_name: str) -> str:\n",
    "    \"\"\"Convenience method for generating image source paths\"\"\"\n",
    "    return os.path.join(cwd, path_name, 'images')\n",
    "\n",
    "def make_dst(path_name: str) -> str:\n",
    "    \"\"\"Convenience method for generating image destination paths\"\"\"\n",
    "    return os.path.join(dst, path_name)\n",
    "\n",
    "src_and_dst: T.List[T.Dict] = [\n",
    "    {'src': make_src('archived-images-chacha'), 'dst': make_dst('chacha')},\n",
    "    {'src': make_src('archived-images-chacourt'), 'dst': make_dst('chacourt')},\n",
    "    {'src': make_src('archived-images-jchere'), 'dst': make_dst('jchere')},\n",
    "    {'src': make_src('archived-images-jcpremium'), 'dst': make_dst('jcpremium')},\n",
    "    {'src': make_src('archived-images-kauctioncar'), 'dst': make_dst('kauctioncar')},\n",
    "    {'src': make_src('archived-images-usedcarmall'), 'dst': make_dst('usedcarmall')},\n",
    "    {'src': make_src('archived-images-encar'), 'dst': make_dst('encar')},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encar_categories = {}\n",
    "with open('vehicle_names_refined.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if row and row[0]:\n",
    "            to_encar_categories[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources: T.List[T.List] = []\n",
    "    \n",
    "for obj in src_and_dst:\n",
    "    ds_store = os.path.join(obj['src'], '.DS_Store')\n",
    "    if os.path.exists(ds_store):\n",
    "        os.remove(ds_store)\n",
    "    \n",
    "    if not os.path.exists(obj['dst']):\n",
    "        os.mkdir(obj['dst'])\n",
    "                \n",
    "    all_sources += [{\n",
    "        'src': os.path.join(obj['src'], n),\n",
    "        'dst': obj['dst'],\n",
    "        'name': n,\n",
    "    } for n in os.listdir(obj['src'])]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 5] Input/output error\n"
     ]
    }
   ],
   "source": [
    "for obj in all_sources:\n",
    "    n = obj['name']\n",
    "    if n in to_encar_categories:\n",
    "        # create a new path that is mapped to the encar category\n",
    "        dst = os.path.join(obj['dst'], to_encar_categories[n])\n",
    "        # create a directory with that path if it does not yet exist\n",
    "        if not os.path.exists(dst):\n",
    "            os.mkdir(dst)\n",
    "        paths = [{'path': os.path.join(obj['src'], fn), 'name': fn} for fn in os.listdir(obj['src'])]\n",
    "        random.shuffle(paths)\n",
    "        for img_obj in paths:\n",
    "            if '.DS_Store' in img_obj['path']:\n",
    "                os.remove(img_obj['path'])\n",
    "                continue\n",
    "            if os.path.exists(os.path.join(dst, img_obj['name'])):\n",
    "                continue\n",
    "            try:\n",
    "                shutil.copy2(img_obj['path'], dst)\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Discussion*\n",
    "\n",
    "> It turns out that the greatest source of erroneous labeling was Usecarmall/Foreign vehicles. Our used car expert was able to manually relabel many of the problematic photos from this source. As a result, we can be confident that our image data set is clean and correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
